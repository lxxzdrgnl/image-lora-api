import torch
from diffusers import StableDiffusionPipeline
from peft import PeftModel
import argparse
from datetime import datetime
import os

# ----------------------------
# 1ï¸âƒ£ í™˜ê²½ ì„¤ì •
# ----------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
model_id = "xyn-ai/anything-v4.0"  # Anything v4.0 (ì• ë‹ˆë©”ì´ì…˜/ë§Œí™” íŠ¹í™”)

print(f"Using device: {device}")

# ----------------------------
# 2ï¸âƒ£ ì¸ì íŒŒì‹±
# ----------------------------
parser = argparse.ArgumentParser(description="í•™ìŠµëœ LoRA ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±")
parser.add_argument(
    "--prompt",
    type=str,
    default="mycharacter, black and white manga style, monochrome illustration",
    help="ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸"
)
parser.add_argument(
    "--negative_prompt",
    type=str,
    default="color, colorful, low quality, blurry",
    help="ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸"
)
parser.add_argument(
    "--lora_path",
    type=str,
    default="my_lora_model",
    help="LoRA ëª¨ë¸ ê²½ë¡œ"
)
parser.add_argument(
    "--output_dir",
    type=str,
    default="outputs",
    help="ìƒì„±ëœ ì´ë¯¸ì§€ ì €ì¥ í´ë”"
)
parser.add_argument(
    "--num_images",
    type=int,
    default=1,
    help="ìƒì„±í•  ì´ë¯¸ì§€ ê°œìˆ˜"
)
parser.add_argument(
    "--steps",
    type=int,
    default=25,
    help="Inference steps (ë†’ì„ìˆ˜ë¡ í’ˆì§ˆ í–¥ìƒ, ì‹œê°„ ì¦ê°€)"
)
parser.add_argument(
    "--guidance_scale",
    type=float,
    default=7.5,
    help="CFG scale (ë†’ì„ìˆ˜ë¡ í”„ë¡¬í”„íŠ¸ ì¶©ì‹¤ë„ ì¦ê°€)"
)
parser.add_argument(
    "--seed",
    type=int,
    default=None,
    help="ëœë¤ ì‹œë“œ (ì¬í˜„ì„±ì„ ìœ„í•´ ì‚¬ìš©)"
)

args = parser.parse_args()

# ----------------------------
# 3ï¸âƒ£ Stable Diffusion íŒŒì´í”„ë¼ì¸ ë¡œë“œ
# ----------------------------
print(f"\nLoading Stable Diffusion model from {model_id}...")
pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    safety_checker=None  # ì•ˆì „ ê²€ì‚¬ê¸° ë¹„í™œì„±í™” (ì†ë„ í–¥ìƒ)
)

# ----------------------------
# 4ï¸âƒ£ LoRA ëª¨ë¸ ë¡œë“œ
# ----------------------------
print(f"Loading LoRA weights from {args.lora_path}...")
pipe.unet = PeftModel.from_pretrained(
    pipe.unet,
    args.lora_path,
    torch_dtype=torch.float16
)

pipe.to(device)
pipe.unet.eval()

print("Model loaded successfully!")

# ----------------------------
# 5ï¸âƒ£ ì¶œë ¥ í´ë” ìƒì„±
# ----------------------------
os.makedirs(args.output_dir, exist_ok=True)

# ----------------------------
# 6ï¸âƒ£ ì´ë¯¸ì§€ ìƒì„±
# ----------------------------
print(f"\nGenerating {args.num_images} image(s)...")
print(f"Prompt: {args.prompt}")
print(f"Negative prompt: {args.negative_prompt}")
print(f"Steps: {args.steps}, Guidance scale: {args.guidance_scale}")

# ì‹œë“œ ì„¤ì • (ì¬í˜„ì„±)
if args.seed is not None:
    generator = torch.Generator(device=device).manual_seed(args.seed)
    print(f"Seed: {args.seed}")
else:
    generator = None

for i in range(args.num_images):
    print(f"\nGenerating image {i+1}/{args.num_images}...")

    with torch.no_grad():
        image = pipe(
            prompt=args.prompt,
            negative_prompt=args.negative_prompt,
            num_inference_steps=args.steps,
            guidance_scale=args.guidance_scale,
            generator=generator
        ).images[0]

    # íŒŒì¼ëª… ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{timestamp}_{i+1}.png"
    output_path = os.path.join(args.output_dir, filename)

    # ì´ë¯¸ì§€ ì €ì¥
    image.save(output_path)
    print(f"Saved: {output_path}")

print(f"\nâœ… All images generated successfully!")
print(f"ğŸ“ Output folder: {args.output_dir}")
